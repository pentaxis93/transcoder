#!/usr/bin/env python3
"""
Video Transcoder Script with Resume Capability and Special Character Handling
Transcodes video files using ffmpeg with H.265/HEVC encoding optimized for small file size.
Supports resuming interrupted batch operations and handles all special characters in filenames.

Usage: python3 transcode.py [input_directory] [options]
"""

import os
import sys
import subprocess
import argparse
import logging
import json
import time
import shutil
import hashlib
import unicodedata
from pathlib import Path
from datetime import datetime
from typing import Tuple, List, Dict, Optional, Set

# Constants
VIDEO_EXTENSIONS = ['.mp4', '.avi', '.mkv', '.mov',
                    '.wmv', '.flv', '.webm', '.m4v', '.3gp']
MIN_FILE_SIZE = 1000  # 1KB minimum for valid video
MIN_OUTPUT_SIZE = 10000  # 10KB minimum for valid output
STATE_FILE = "transcode_state.json"

# ANSI color codes


class Colors:
    RESET = "\033[0m"
    BOLD = "\033[1m"
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN = "\033[96m"
    GREY = "\033[90m"


def supports_color() -> bool:
    """Check if terminal supports colors."""
    return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty() and os.name != 'nt'


USE_COLORS = supports_color()


def colorize(text: str, color: str) -> str:
    """Add color to text if supported."""
    return f"{color}{text}{Colors.RESET}" if USE_COLORS else text


def setup_logging(log_dir: Path = Path('.')) -> Tuple[logging.Logger, logging.Logger, str]:
    """Set up file and console loggers."""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f"transcode_log_{timestamp}.log"

    # File logger with full details
    file_logger = logging.getLogger("file_logger")
    file_logger.setLevel(logging.DEBUG)
    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'))
    file_logger.addHandler(file_handler)

    # Console logger without file paths
    console_logger = logging.getLogger("console_logger")
    console_logger.setLevel(logging.INFO)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'))
    console_logger.addHandler(console_handler)

    return file_logger, console_logger, str(log_file)


def get_safe_temp_filename(original_path: Path, work_dir: Path) -> Path:
    """Generate a safe temporary filename for work directory."""
    # Create a hash of the original path to ensure uniqueness
    path_hash = hashlib.md5(
        str(original_path).encode('utf-8')).hexdigest()[:12]

    # Get the original extension
    extension = original_path.suffix if original_path.suffix else '.mp4'

    # Create a safe filename with timestamp and hash
    timestamp = int(time.time() * 1000)  # milliseconds for extra uniqueness
    safe_filename = f"transcode_{timestamp}_{path_hash}{extension}"

    return work_dir / safe_filename


def normalize_path(path: Path) -> str:
    """Normalize a path for safe use with subprocess."""
    # Convert to absolute path to avoid relative path issues
    abs_path = path.absolute()

    # On Windows, we might need to handle UNC paths differently
    if os.name == 'nt':
        path_str = str(abs_path)
        # Ensure Windows paths are properly formatted
        if not path_str.startswith('\\\\'):
            path_str = os.path.normpath(path_str)
    else:
        # On Unix-like systems, just convert to string
        path_str = str(abs_path)

    return path_str


class TranscodeState:
    """Manages the state of the transcoding batch operation."""

    def __init__(self, state_file: Path = Path(STATE_FILE)):
        self.state_file = state_file
        self.state = {
            "version": "1.1",
            "input_dir": "",
            "start_time": None,
            "last_update": None,
            "completed": {},  # {filepath: "success"|"larger"|"failed"}
            "failed_reasons": {},  # {filepath: error_message}
            "in_progress": None,
            "temp_mappings": {},  # {original_path: temp_filename} for recovery
            "statistics": {
                "total_files": 0,
                "processed": 0,
                "successful": 0,
                "larger": 0,
                "failed": 0,
                "total_original_size": 0,
                "total_new_size": 0
            }
        }

    def load(self, input_dir: str) -> bool:
        """Load state from file if it exists and matches input directory."""
        if not self.state_file.exists():
            return False

        try:
            with open(self.state_file, 'r', encoding='utf-8') as f:
                loaded_state = json.load(f)

            # Check if this is for the same input directory
            if loaded_state.get("input_dir") != input_dir:
                return False

            self.state = loaded_state
            return True
        except (json.JSONDecodeError, KeyError):
            return False

    def save(self):
        """Save current state to file."""
        self.state["last_update"] = time.time()
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def initialize(self, input_dir: str, total_files: int):
        """Initialize state for a new batch."""
        self.state["input_dir"] = input_dir
        self.state["start_time"] = time.time()
        self.state["statistics"]["total_files"] = total_files
        self.save()

    def is_processed(self, filepath: str) -> bool:
        """Check if a file has already been processed."""
        return str(filepath) in self.state["completed"]

    def get_status(self, filepath: str) -> Optional[str]:
        """Get the status of a processed file."""
        return self.state["completed"].get(str(filepath))

    def mark_completed(self, filepath: str, status: str, error_msg: Optional[str] = None,
                       original_size: int = 0, new_size: int = 0):
        """Mark a file as completed with its status."""
        filepath_str = str(filepath)
        self.state["completed"][filepath_str] = status

        if error_msg:
            self.state["failed_reasons"][filepath_str] = error_msg

        # Update statistics
        self.state["statistics"]["processed"] += 1
        if status == "success":
            self.state["statistics"]["successful"] += 1
            self.state["statistics"]["total_original_size"] += original_size
            self.state["statistics"]["total_new_size"] += new_size
        elif status == "larger":
            self.state["statistics"]["larger"] += 1
            self.state["statistics"]["total_original_size"] += original_size
            self.state["statistics"]["total_new_size"] += new_size
        elif status == "failed":
            self.state["statistics"]["failed"] += 1

        # Clear in-progress and temp mapping
        self.state["in_progress"] = None
        if filepath_str in self.state["temp_mappings"]:
            del self.state["temp_mappings"][filepath_str]

        self.save()

    def mark_in_progress(self, filepath: str, temp_filename: str):
        """Mark a file as currently being processed."""
        filepath_str = str(filepath)
        self.state["in_progress"] = filepath_str
        self.state["temp_mappings"][filepath_str] = temp_filename
        self.save()

    def get_temp_mapping(self, filepath: str) -> Optional[str]:
        """Get the temporary filename for a file."""
        return self.state["temp_mappings"].get(str(filepath))

    def get_completed_files(self) -> Dict[str, str]:
        """Get all completed files and their statuses."""
        return self.state["completed"].copy()

    def get_statistics(self) -> Dict:
        """Get current statistics."""
        return self.state["statistics"].copy()

    def clear(self):
        """Clear the state file."""
        if self.state_file.exists():
            self.state_file.unlink()


def human_size(bytes: int) -> str:
    """Convert bytes to human readable format."""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes < 1024.0:
            return f"{bytes:.2f} {unit}"
        bytes /= 1024.0
    return f"{bytes:.2f} PB"


def find_video_files(input_dir: Path) -> Tuple[List[Path], List[Path]]:
    """Find all video files and empty directories."""
    video_files = []
    all_dirs = set()
    dirs_with_videos = set()

    for root, dirs, files in os.walk(input_dir):
        root_path = Path(root)
        all_dirs.add(root_path)

        # Check for video files
        video_found = False
        for file in files:
            if any(file.lower().endswith(ext) for ext in VIDEO_EXTENSIONS):
                video_files.append(root_path / file)
                video_found = True

        if video_found:
            # Mark this directory and all parents as having videos
            current = root_path
            while current != input_dir.parent:
                dirs_with_videos.add(current)
                current = current.parent

    empty_dirs = sorted(all_dirs - dirs_with_videos)
    return video_files, empty_dirs


def get_video_metadata(video_path: Path) -> Optional[Dict]:
    """Get video metadata using ffprobe."""
    try:
        # Normalize the path for subprocess
        video_path_str = normalize_path(video_path)

        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json",
            "-show_format", "-show_streams", video_path_str
        ]

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30,
            shell=False  # Important: use shell=False for proper argument handling
        )

        if result.returncode == 0:
            return json.loads(result.stdout)
    except (subprocess.SubprocessError, json.JSONDecodeError, subprocess.TimeoutExpired) as e:
        # Log the error for debugging
        print(f"Debug: ffprobe error for {video_path.name}: {e}")
    return None


def extract_video_info(metadata: Optional[Dict]) -> Dict:
    """Extract relevant information from video metadata."""
    info = {
        "duration": 0,
        "width": "unknown",
        "height": "unknown",
        "bitrate": "unknown",
        "codec": "unknown",
        "audio": {"codec": "none", "channels": "none", "bitrate": "none"}
    }

    if not metadata:
        return info

    # Duration
    if "format" in metadata and "duration" in metadata["format"]:
        try:
            info["duration"] = float(metadata["format"]["duration"])
        except (ValueError, TypeError):
            pass

    # Video stream info
    for stream in metadata.get("streams", []):
        if stream.get("codec_type") == "video":
            info["width"] = stream.get("width", "unknown")
            info["height"] = stream.get("height", "unknown")
            info["codec"] = stream.get("codec_name", "unknown")
            if "bit_rate" in stream:
                try:
                    info["bitrate"] = int(stream["bit_rate"])
                except (ValueError, TypeError):
                    pass
        elif stream.get("codec_type") == "audio":
            info["audio"] = {
                "codec": stream.get("codec_name", "unknown"),
                "channels": stream.get("channels", "unknown"),
                "bitrate": stream.get("bit_rate", "unknown")
            }

    # Fallback bitrate from format
    if info["bitrate"] == "unknown" and "format" in metadata and "bit_rate" in metadata["format"]:
        try:
            info["bitrate"] = int(metadata["format"]["bit_rate"])
        except (ValueError, TypeError):
            pass

    return info


def verify_input_file(file_path: Path, file_logger: logging.Logger) -> Tuple[bool, Optional[str]]:
    """Verify input file is valid."""
    if not file_path.exists():
        return False, "File does not exist"

    if not os.access(file_path, os.R_OK):
        return False, "File is not readable"

    try:
        file_size = file_path.stat().st_size
        if file_size < MIN_FILE_SIZE:
            return False, f"File too small ({file_size} bytes)"
    except OSError as e:
        return False, f"Cannot access file: {e}"

    # Verify it's a valid video
    metadata = get_video_metadata(file_path)
    if metadata:
        for stream in metadata.get("streams", []):
            if stream.get("codec_type") == "video":
                return True, None

    return False, "No video stream found"


def create_ffmpeg_command(input_path: Path, output_path: Path) -> List[str]:
    """Create the ffmpeg encoding command with proper path handling."""
    # Normalize paths for subprocess
    input_str = normalize_path(input_path)
    output_str = normalize_path(output_path)

    return [
        "ffmpeg", "-y",
        "-i", input_str,
        "-map", "0:v:0", "-map", "0:a:0?",
        "-c:v", "libx265",
        "-preset", "slower",
        "-x265-params", "limit-refs=3:no-amp=1:rd=4:aq-mode=3:bframes=5:psy-rd=1.0:psy-rdoq=2.0",
        "-crf", "25",
        "-g", "96",
        "-vf", "scale='min(1920,iw)':'min(1080,ih)':force_original_aspect_ratio=decrease,setsar=1:1",
        "-c:a", "aac",
        "-b:a", "64k",
        "-ac", "1",
        "-ar", "44100",
        "-pix_fmt", "yuv420p",
        "-profile:v", "main", "-level", "4.1",
        "-movflags", "+faststart",
        "-metadata", "title=", "-metadata", "comment=",
        "-threads", "0",
        "-v", "warning",
        output_str
    ]


def monitor_progress(process: subprocess.Popen, duration: float, index: int, total: int,
                     output_path: Path) -> Tuple[int, bool, str]:
    """Monitor ffmpeg progress and display updates."""
    start_time = time.time()
    last_update = start_time
    term_width = shutil.get_terminal_size().columns

    # Initial message
    print(f"\r[{index}/{total}] Starting encoding...", end="", flush=True)

    while process.poll() is None:
        time.sleep(0.1)
        current_time = time.time()
        elapsed = current_time - start_time

        # Update display every second
        if (current_time - last_update) >= 1.0:
            last_update = current_time

            # Check output file
            file_size = 0
            file_status = "waiting..."
            if output_path.exists():
                try:
                    file_size = output_path.stat().st_size
                    file_status = f"output: {human_size(file_size)}"
                except OSError:
                    pass

            # Calculate progress
            if duration > 0:
                progress = min(95, (elapsed / (duration * 1.5)) * 100)
                bar_length = min(20, term_width - 80)
                filled = int(bar_length * progress / 100)

                # Color based on progress
                if progress < 33:
                    bar_color = Colors.RED
                elif progress < 66:
                    bar_color = Colors.YELLOW
                else:
                    bar_color = Colors.GREEN

                bar = colorize('█' * filled, bar_color) + \
                    colorize('░' * (bar_length - filled), Colors.GREY)

                # ETA calculation
                eta_str = ""
                if progress > 0:
                    eta_seconds = (elapsed / progress * 100) - elapsed
                    eta_str = f" | ETA: {int(eta_seconds/60)}m {int(eta_seconds % 60)}s"

                # Format display
                elapsed_str = f"{int(elapsed/60)}m {int(elapsed % 60)}s"
                progress_msg = f"[{index}/{total}] [{bar}] {progress:.1f}% | {elapsed_str} [{file_status}]{eta_str}"
            else:
                # No duration info
                elapsed_str = f"{int(elapsed/60)}m {int(elapsed % 60)}s"
                progress_msg = f"[{index}/{total}] Processing... {elapsed_str} [{file_status}]"

            print(f"\r{progress_msg:<{term_width-1}}", end="", flush=True)

    # Get final status
    returncode = process.returncode
    file_created = output_path.exists() and output_path.stat().st_size > MIN_OUTPUT_SIZE

    # Get error output if available
    error_output = ""
    if hasattr(process, 'stderr'):
        try:
            _, stderr = process.communicate(timeout=1)
            error_output = stderr if stderr else ""
        except:
            pass

    # Final message
    total_time = time.time() - start_time
    final_msg = f"[{index}/{total}] Encoding completed in {int(total_time/60)}m {int(total_time % 60)}s"
    if file_created:
        final_size = output_path.stat().st_size
        final_msg += f" [{human_size(final_size)}]"
    print(f"\r{colorize(final_msg, Colors.GREEN if file_created else Colors.RED):<{term_width-1}}")

    return returncode, file_created, error_output


def print_transcoding_summary(index: int, total: int, original_info: Dict,
                              original_size: int, new_size: int, is_larger: bool):
    """Print detailed transcoding summary."""
    print("\n" + "─" * 50)
    print(colorize("    TRANSCODING SUMMARY", Colors.BOLD + Colors.CYAN))
    print("─" * 50)

    print(f"    File: {colorize(f'#{index}', Colors.BOLD)} of {total}")

    # Before/After comparison
    print(
        f"\n    {colorize('BEFORE:', Colors.YELLOW):<25} {colorize('AFTER:', Colors.GREEN)}")
    print(
        f"    Resolution:  {original_info['width']}x{original_info['height']}")

    if original_info['bitrate'] != 'unknown':
        print(f"    Bitrate:     {original_info['bitrate']/1000:.1f} kbps")

    print(
        f"    Size:        {human_size(original_size):<20} {human_size(new_size)}")

    # Space savings
    savings = original_size - new_size
    savings_pct = (savings / original_size * 100) if original_size > 0 else 0
    savings_str = f"{human_size(abs(savings))} ({abs(savings_pct):.1f}%)"

    if is_larger:
        print(
            f"    Space saved: {colorize('-' + savings_str + ' (larger)', Colors.MAGENTA)}")
    else:
        print(f"    Space saved: {colorize(savings_str, Colors.GREEN)}")

    # Encoding settings
    print(f"\n    {colorize('ENCODING SETTINGS:', Colors.CYAN)}")
    print("    Video codec:   H.265/HEVC")
    print("    Quality:       CRF 25")
    print("    Preset:        slower")
    print("    Resolution:    max 1080p")
    print("    Framerate:     24 fps")
    print("    Audio:         64k mono AAC")
    print("─" * 50)


def transcode_video(input_file: Path, work_dir: Path, index: int, total: int,
                    file_logger: logging.Logger, console_logger: logging.Logger,
                    state: TranscodeState) -> Tuple[bool, Optional[str], bool, int, Optional[Path]]:
    """Transcode a single video file with special character handling."""
    file_logger.info(
        f"Starting transcoding of file #{index}/{total}: {input_file.name}")
    console_logger.info(f"[{index}/{total}] ▶️  Starting transcoding")
    print(colorize(f"[{index}/{total}] ▶️  Starting transcoding", Colors.BLUE))

    try:
        # Verify input file
        valid, error = verify_input_file(input_file, file_logger)
        if not valid:
            error_msg = f"Invalid input file: {error}"
            file_logger.error(f"{error_msg} - {input_file}")
            console_logger.error(f"[{index}/{total}] ❌ {error_msg}")
            return False, error_msg, False, 0, None

        # Get original file info
        original_size = input_file.stat().st_size
        metadata = get_video_metadata(input_file)
        original_info = extract_video_info(metadata)

        # Display file info
        duration_str = f"{original_info['duration']/60:.2f} minutes" if original_info['duration'] > 0 else "Unknown"
        print(f"    Duration: {duration_str}")
        print(f"    Resolution: {original_info['width']}x{original_info['height']}, "
              f"Size: {human_size(original_size)}, Codec: {original_info['codec']}")

        # Create safe temporary output filename
        temp_output = get_safe_temp_filename(input_file, work_dir)
        work_dir.mkdir(parents=True, exist_ok=True)

        # Log the temp filename mapping
        file_logger.info(f"Using temporary filename: {temp_output.name}")

        # Mark as in progress with temp filename
        state.mark_in_progress(str(input_file), temp_output.name)

        # Create and run ffmpeg command
        cmd = create_ffmpeg_command(input_file, temp_output)

        # Log the command for debugging (with safe filenames only)
        file_logger.debug(
            f"FFmpeg command: {' '.join(cmd[:3])} ... [paths] ... {' '.join(cmd[-5:])}")

        # Start process with proper error capture
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            shell=False  # Important: never use shell=True with user input
        )

        # Monitor progress
        returncode, file_created, error_output = monitor_progress(
            process, original_info['duration'], index, total, temp_output
        )

        if returncode != 0 or not file_created:
            error_msg = f"Transcoding failed with code {returncode}"
            if not file_created:
                error_msg += ", no output file created"

            file_logger.error(f"{error_msg} - {input_file}")
            file_logger.error(f"Error output: {error_output}")
            console_logger.error(f"[{index}/{total}] ❌ {error_msg}")

            # Clean up temp file
            if temp_output.exists():
                try:
                    temp_output.unlink()
                except OSError as e:
                    file_logger.error(f"Failed to remove temp file: {e}")

            return False, error_output or error_msg, False, 0, None

        # Check output file
        new_size = temp_output.stat().st_size
        is_larger = new_size >= original_size

        # Print summary
        print_transcoding_summary(
            index, total, original_info, original_size, new_size, is_larger)

        return True, None, is_larger, new_size, temp_output

    except Exception as e:
        error_msg = str(e)
        file_logger.error(f"Error transcoding {input_file}: {error_msg}")
        console_logger.error(f"[{index}/{total}] ❌ Error: {error_msg}")
        return False, error_msg, False, 0, None


def categorize_error(error_message: str) -> str:
    """Categorize error messages."""
    error_patterns = [
        ("No such file or directory", "File Access Error"),
        ("Permission denied", "Permission Error"),
        ("Invalid data found", "Corrupted Video Data"),
        ("Conversion failed", "Encoder Error"),
        ("Out of memory", "Memory Error"),
    ]

    if error_message:
        for pattern, category in error_patterns:
            if pattern in error_message:
                return category

    return "Other Error"


def write_file_lists(state: TranscodeState, empty_dirs: List[Path]):
    """Write summary files based on state."""
    completed_files = state.get_completed_files()

    successful = [f for f, status in completed_files.items()
                  if status == "success"]
    larger = [f for f, status in completed_files.items() if status == "larger"]
    failed = [(f, state.state["failed_reasons"].get(f, "Unknown error"))
              for f, status in completed_files.items() if status == "failed"]

    # Extract just filenames
    successful = [Path(f).name for f in successful]
    larger = [Path(f).name for f in larger]
    failed = [(Path(f).name, err) for f, err in failed]

    # Successful files
    if successful:
        with open("successful_transcodes.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(successful))
        print(colorize(
            f"📝 Wrote {len(successful)} successful files to successful_transcodes.txt", Colors.GREEN))

    # Larger files
    if larger:
        with open("larger_transcodes.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(larger))
        print(colorize(
            f"📝 Wrote {len(larger)} larger files to larger_transcodes.txt", Colors.MAGENTA))

    # Failed files
    if failed or empty_dirs:
        with open("failed_transcodes.txt", 'w', encoding='utf-8') as f:
            if failed:
                # Group by error category
                errors_by_category = {}
                for filename, error in failed:
                    category = categorize_error(error)
                    if category not in errors_by_category:
                        errors_by_category[category] = []
                    errors_by_category[category].append((filename, error))

                f.write(f"FAILED TRANSCODES BY ERROR CATEGORY\n")
                f.write(f"Total failed: {len(failed)}\n\n")

                for category, files in sorted(errors_by_category.items()):
                    f.write(f"{category.upper()} ({len(files)}):\n")
                    for filename, error in files:
                        condensed = error.replace('\n', ' ').strip()[:100]
                        f.write(f"- {filename} | {condensed}\n")
                    f.write("\n")

            if empty_dirs:
                f.write(
                    f"\nDIRECTORIES WITHOUT VIDEO FILES ({len(empty_dirs)}):\n")
                for dir_path in empty_dirs:
                    f.write(f"- {dir_path}\n")

        print(
            colorize(f"📝 Wrote failed files list to failed_transcodes.txt", Colors.YELLOW))


def print_final_summary(stats: Dict, elapsed: float, log_file: str):
    """Print final batch summary."""
    hours = int(elapsed / 3600)
    mins = int((elapsed % 3600) / 60)
    secs = int(elapsed % 60)

    print("\n" + "═" * 70)
    print(colorize("  BATCH TRANSCODE SUMMARY", Colors.BOLD + Colors.CYAN))
    print("═" * 70)

    print(colorize("\n  RESULTS", Colors.BOLD))
    print(
        f"  ✅ Successfully transcoded (smaller): {stats['successful']} files")
    print(f"  📊 Successfully transcoded (larger): {stats['larger']} files")
    print(f"  ❌ Failed to transcode: {stats['failed']} files")

    print(colorize("\n  SPACE SAVINGS", Colors.BOLD))
    print(
        f"  💾 Total original size: {human_size(stats['total_original_size'])}")
    print(f"  💾 Total new size: {human_size(stats['total_new_size'])}")

    savings = stats['total_original_size'] - stats['total_new_size']
    savings_pct = (savings / stats['total_original_size']
                   * 100) if stats['total_original_size'] > 0 else 0
    savings_text = f"  🔽 Total space saved: {human_size(abs(savings))} ({abs(savings_pct):.1f}%)"
    print(colorize(savings_text, Colors.GREEN if savings > 0 else Colors.RED))

    print(colorize("\n  TIME STATISTICS", Colors.BOLD))
    print(f"  🕒 Total processing time: {hours}h {mins}m {secs}s")

    if stats['successful'] + stats['larger'] > 0:
        avg_time = elapsed / (stats['successful'] + stats['larger'])
        print(
            f"  🕒 Average time per file: {int(avg_time/60)}m {int(avg_time % 60)}s")

    print(colorize("\n  FILE LOCATIONS", Colors.BOLD))
    print(f"  📝 Log file: {log_file}")
    print(f"  📋 Successful files list: successful_transcodes.txt")
    print(f"  📋 Larger output files list: larger_transcodes.txt")
    print(f"  📋 Failed files list: failed_transcodes.txt")
    print("═" * 70)


def clean_work_directory(work_dir: Path, state: TranscodeState, file_logger: logging.Logger):
    """Clean up work directory and handle interrupted files."""
    cleaned_count = 0

    # Get the temp filename if there was an interrupted file
    interrupted_temp = None
    if state.state["in_progress"]:
        interrupted_temp = state.get_temp_mapping(state.state["in_progress"])

    for file in work_dir.glob('*'):
        try:
            # Check if this is the interrupted file
            if interrupted_temp and file.name == interrupted_temp:
                file_logger.info(
                    f"Removing interrupted file from work directory: {file.name}")
                print(
                    colorize(f"🔧 Removing interrupted file: {file.name}", Colors.YELLOW))

            file.unlink()
            cleaned_count += 1
        except OSError as e:
            file_logger.error(f"Failed to remove work file {file.name}: {e}")

    if cleaned_count > 0:
        print(colorize(
            f"🔧 Cleaned {cleaned_count} file(s) from work directory", Colors.YELLOW))


def main():
    # Parse arguments
    parser = argparse.ArgumentParser(
        description="Video Transcoder Script with Resume Capability")
    parser.add_argument(
        "input_dir", help="Input directory containing video files")
    parser.add_argument("-s", "--success_dir", default="transcoded_success",
                        help="Output directory for successfully transcoded files")
    parser.add_argument("-e", "--error_dir", default="transcoded_error",
                        help="Output directory for files that failed transcoding")
    parser.add_argument("-l", "--larger_dir", default="transcoded_larger",
                        help="Output directory for transcoded files larger than original")
    parser.add_argument("-w", "--work_dir", default="work_in_progress",
                        help="Temporary directory for files being processed")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="Enable verbose logging")
    parser.add_argument("--fresh", action="store_true",
                        help="Start fresh, ignoring any previous state")
    args = parser.parse_args()

    # Setup
    file_logger, console_logger, log_file = setup_logging()

    # Print header
    print("\n" + "═" * 70)
    print(colorize("  VIDEO TRANSCODER", Colors.BOLD + Colors.CYAN))
    print(colorize("  Optimized for small size and mobile viewing", Colors.CYAN))
    print("═" * 70 + "\n")

    # Verify ffmpeg is available
    try:
        subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
        print(colorize("✅ ffmpeg is available", Colors.GREEN))
    except (subprocess.SubprocessError, FileNotFoundError):
        print(colorize("❌ ffmpeg not found. Please install ffmpeg.", Colors.RED))
        sys.exit(1)

    # Setup directories
    input_dir = Path(args.input_dir)
    if not input_dir.is_dir():
        print(
            colorize(f"❌ Input directory not found: {input_dir}", Colors.RED))
        sys.exit(1)

    success_dir = Path(args.success_dir)
    error_dir = Path(args.error_dir)
    larger_dir = Path(args.larger_dir)
    work_dir = Path(args.work_dir)

    # Create directories
    for directory in [success_dir, error_dir, larger_dir, work_dir]:
        directory.mkdir(exist_ok=True)

    # Initialize state manager
    state = TranscodeState()

    # Check for existing state
    resumed = False
    if not args.fresh and state.load(str(input_dir.absolute())):
        resumed = True
        print(colorize(
            "📂 Found previous state file - resuming batch operation", Colors.CYAN))

        stats = state.get_statistics()
        print(
            f"    Previously processed: {stats['processed']}/{stats['total_files']} files")
        print(
            f"    Successful: {stats['successful']}, Larger: {stats['larger']}, Failed: {stats['failed']}")

        # Clean work directory if there was an interrupted file
        if state.state["in_progress"]:
            print(colorize(
                f"⚠️  Found interrupted file: {Path(state.state['in_progress']).name}", Colors.YELLOW))
            clean_work_directory(work_dir, state, file_logger)

        print("")
    elif args.fresh and state.state_file.exists():
        state.clear()
        print(colorize("🗑️  Cleared previous state - starting fresh", Colors.YELLOW))

    # Find video files
    print(colorize("🔍 Searching for video files...", Colors.BLUE))
    video_files, empty_dirs = find_video_files(input_dir)

    if not video_files:
        print(colorize("❌ No video files found.", Colors.RED))
        if empty_dirs:
            print(colorize(
                f"📁 Found {len(empty_dirs)} directories without videos", Colors.YELLOW))
            write_file_lists(state, empty_dirs)
        sys.exit(0)

    # Filter out already processed files if resuming
    if resumed:
        original_count = len(video_files)
        video_files = [
            f for f in video_files if not state.is_processed(str(f))]
        skipped = original_count - len(video_files)
        if skipped > 0:
            print(
                colorize(f"⏭️  Skipping {skipped} already processed files", Colors.CYAN))

    print(
        colorize(f"📁 Found {len(video_files)} video files to transcode", Colors.GREEN))
    if empty_dirs:
        print(colorize(
            f"📁 Found {len(empty_dirs)} directories without videos", Colors.YELLOW))

    # Initialize state if not resumed
    if not resumed:
        total_files = len(video_files) + (state.get_statistics()
                                          ['processed'] if resumed else 0)
        state.initialize(str(input_dir.absolute()), total_files)

    # Clean work directory if not resuming
    if not resumed:
        for file in work_dir.glob('*'):
            try:
                file.unlink()
            except OSError:
                pass

    # Initialize tracking
    start_time = time.time()
    if resumed and state.state["start_time"]:
        original_start_time = state.state["start_time"]
    else:
        original_start_time = start_time

    print("\n" + "═" * 70)
    print(colorize("  STARTING BATCH TRANSCODING", Colors.BOLD + Colors.YELLOW))
    if resumed:
        print(colorize("  (RESUMED FROM PREVIOUS RUN)", Colors.YELLOW))
    print("═" * 70)

    # Process each video
    current_stats = state.get_statistics()
    total_count = current_stats['total_files']

    for video_file in video_files:
        # Calculate actual position in overall batch
        current_index = current_stats['processed'] + 1

        print(colorize(f"\n[{current_index}/{total_count}] Processing {current_index/total_count*100:.1f}% complete",
                       Colors.BOLD + Colors.BLUE))
        print("─" * 50)

        # Get original size
        try:
            original_size = video_file.stat().st_size
        except OSError:
            original_size = 0

        # Transcode
        success, error, is_larger, new_size, temp_output = transcode_video(
            video_file, work_dir, current_index, total_count, file_logger, console_logger, state
        )

        if success and temp_output:
            # Move to appropriate directory using original filename
            if is_larger:
                destination = larger_dir / video_file.name
                status = "larger"
            else:
                destination = success_dir / video_file.name
                status = "success"

            try:
                shutil.move(str(temp_output), str(destination))
                print(colorize(f"🔄 Moved to {status} directory",
                               Colors.MAGENTA if is_larger else Colors.GREEN))

                # Mark as completed
                state.mark_completed(
                    str(video_file), status, None, original_size, new_size)

            except OSError as e:
                # Mark as failed if move fails
                state.mark_completed(
                    str(video_file), "failed", f"Move failed: {e}")
                if temp_output.exists():
                    temp_output.unlink()
        else:
            # Copy original to error directory
            try:
                shutil.copy2(video_file, error_dir / video_file.name)
                print(colorize("📋 Copied original to error directory", Colors.YELLOW))
            except OSError:
                pass

            # Mark as failed
            state.mark_completed(str(video_file), "failed",
                                 error or "Unknown error")

        # Update current stats for next iteration
        current_stats = state.get_statistics()

    # Write summary files
    write_file_lists(state, empty_dirs)

    # Print final summary
    final_stats = state.get_statistics()
    total_elapsed = time.time() - original_start_time
    print_final_summary(final_stats, total_elapsed, log_file)

    # Clear state file after successful completion
    state.clear()
    print(colorize("\n✅ Batch processing completed - state file cleared", Colors.GREEN))

    # Final logging
    file_logger.info(f"Batch complete: {final_stats['successful']} successful, "
                     f"{final_stats['larger']} larger, {final_stats['failed']} failed")


if __name__ == "__main__":
    main()
